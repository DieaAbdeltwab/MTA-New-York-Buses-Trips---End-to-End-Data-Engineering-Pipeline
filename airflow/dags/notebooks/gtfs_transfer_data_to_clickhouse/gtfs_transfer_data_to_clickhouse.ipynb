{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2576781-c705-43ba-ba0f-fde56b5ab6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec7ba79-3830-4b36-a137-5d425d36436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Spark session ----------\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read from PostgreSQL\") \\\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \"org.postgresql:postgresql:42.7.7,com.clickhouse:clickhouse-jdbc:0.4.6\"\n",
    "    ) \\\n",
    "    .config(\"spark.executor.cores\", \"8\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b626c4a2-5cb9-4c23-a0b3-a3a373116723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postgres Config Connection\n",
    "\n",
    "jdbc_url_pg = \"jdbc:postgresql://postgres:5432/gtfs_batch\"\n",
    "pg_properties = {\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"password\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0e47665-7dda-4751-8f4c-1915963fc18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tables and store them in DataFrames with filtering is_current = true\n",
    "\n",
    "agency_df = spark.read.jdbc(\n",
    "    url=jdbc_url_pg,\n",
    "    table=\"(SELECT * FROM agency WHERE is_current = true) AS agency\",\n",
    "    properties=pg_properties\n",
    ")\n",
    "\n",
    "calendar_df = spark.read.jdbc(\n",
    "    url=jdbc_url_pg,\n",
    "    table=\"(SELECT * FROM calendar WHERE is_current = true) AS calendar\",\n",
    "    properties=pg_properties\n",
    ")\n",
    "\n",
    "calendar_dates_df = spark.read.jdbc(\n",
    "    url=jdbc_url_pg,\n",
    "    table=\"(SELECT * FROM calendar_dates WHERE is_current = true) AS calendar_dates\",\n",
    "    properties=pg_properties\n",
    ")\n",
    "\n",
    "routes_df = spark.read.jdbc(\n",
    "    url=jdbc_url_pg,\n",
    "    table=\"(SELECT * FROM routes WHERE is_current = true) AS routes\",\n",
    "    properties=pg_properties\n",
    ")\n",
    "\n",
    "shapes_df = spark.read.jdbc(\n",
    "    url=jdbc_url_pg,\n",
    "    table=\"(SELECT * FROM shapes WHERE is_current = true) AS shapes\",\n",
    "    properties=pg_properties\n",
    ")\n",
    "\n",
    "stops_df = spark.read.jdbc(\n",
    "    url=jdbc_url_pg,\n",
    "    table=\"(SELECT * FROM stops WHERE is_current = true) AS stops\",\n",
    "    properties=pg_properties\n",
    ")\n",
    "\n",
    "stop_times_df = spark.read.jdbc(\n",
    "    url=jdbc_url_pg,\n",
    "    table=\"(SELECT * FROM stop_times WHERE is_current = true) AS stop_times\",\n",
    "    properties=pg_properties\n",
    ")\n",
    "\n",
    "trips_df = spark.read.jdbc(\n",
    "    url=jdbc_url_pg,\n",
    "    table=\"(SELECT * FROM trips WHERE is_current = true) AS trips\",\n",
    "    properties=pg_properties\n",
    ")\n",
    "\n",
    "\n",
    "# agency_df         = spark.read.jdbc(url=jdbc_url_pg, table=\"agency\", properties=pg_properties)\n",
    "# calendar_df       = spark.read.jdbc(url=jdbc_url_pg, table=\"calendar\", properties=pg_properties)\n",
    "# calendar_dates_df = spark.read.jdbc(url=jdbc_url_pg, table=\"calendar_dates\", properties=pg_properties)\n",
    "# routes_df         = spark.read.jdbc(url=jdbc_url_pg, table=\"routes\", properties=pg_properties)\n",
    "# shapes_df         = spark.read.jdbc(url=jdbc_url_pg, table=\"shapes\", properties=pg_properties)\n",
    "# stops_df          = spark.read.jdbc(url=jdbc_url_pg, table=\"stops\", properties=pg_properties)\n",
    "# stop_times_df     = spark.read.jdbc(url=jdbc_url_pg, table=\"stop_times\", properties=pg_properties)\n",
    "# trips_df          = spark.read.jdbc(url=jdbc_url_pg, table=\"trips\", properties=pg_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33033246-6e3e-4004-a933-d23b46bfee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================================================================================\n",
    "#=================================================================================================================\n",
    "#=================================================================================================================\n",
    "#=================================================================================================================\n",
    "#=================================================================================================================\n",
    "#=================================================================================================================\n",
    "#=================================================================================================================\n",
    "#================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c7b68-965e-4bbd-9724-05ba7d61e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format, current_date, col, dayofweek, lit\n",
    "\n",
    "# 1. Today's date in yyyyMMdd (integer) format\n",
    "today_str = spark.createDataFrame([(1,)], [\"dummy\"]) \\\n",
    "    .select(current_date().alias(\"today\")) \\\n",
    "    .collect()[0][\"today\"]\n",
    "\n",
    "# today_int = int(\n",
    "#     spark.createDataFrame([(1,)], [\"dummy\"])\n",
    "#          .select(date_format(current_date(), \"yyyyMMdd\").alias(\"today\"))\n",
    "#          .collect()[0][\"today\"]\n",
    "# )\n",
    "\n",
    "# 2. Day of the week number (Spark: Sunday=1, Saturday=7)\n",
    "today_dow = spark.createDataFrame([(1,)], [\"dummy\"]) \\\n",
    "    .select(dayofweek(current_date()).alias(\"dow\")) \\\n",
    "    .collect()[0][\"dow\"]\n",
    "\n",
    "# 3. Filter calendar_df for current day (in range + weekday enabled)\n",
    "days_map = {1: \"sunday\", 2: \"monday\", 3: \"tuesday\", 4: \"wednesday\",\n",
    "            5: \"thursday\", 6: \"friday\", 7: \"saturday\"}\n",
    "\n",
    "calendar_today_df = calendar_df.filter(\n",
    "    (col(\"start_date\") <= lit(today_str).cast(\"date\")) &\n",
    "    (col(\"end_date\") >= lit(today_str).cast(\"date\")) &\n",
    "    (col(days_map[today_dow]) == 1)\n",
    ")\n",
    "\n",
    "# calendar_today_df = calendar_df.filter(\n",
    "#     (col(\"start_date\") <= today_int) &\n",
    "#     (col(\"end_date\") >= today_int) &\n",
    "#     (col(days_map[today_dow]) == 1)\n",
    "# )\n",
    "\n",
    "# 4. Filter calendar_dates_df to the current day\n",
    "calendar_dates_today_df = calendar_dates_df.filter(col(\"date\") == lit(today_str).cast(\"date\"))\n",
    "\n",
    "# 5. Merge the service_id from the two (calendar and calendar_dates)\n",
    "service_today_df = calendar_today_df.select(\"service_id\") \\\n",
    "    .union(calendar_dates_today_df.select(\"service_id\")) \\\n",
    "    .distinct()\n",
    "\n",
    "# 6. Joining with trips\n",
    "trips_today_df = trips_df.join(service_today_df, \"service_id\", \"inner\").select(trips_df[\"*\"])\n",
    "\n",
    "# 7. Remaining DataFrames for the day (with original columns only)\n",
    "stop_times_today_df = stop_times_df.join(trips_today_df, \"trip_id\", \"inner\").select(stop_times_df[\"*\"]).distinct()\n",
    "routes_today_df = routes_df.join(trips_today_df, \"route_id\", \"inner\").select(routes_df[\"*\"]).distinct()\n",
    "shapes_today_df = shapes_df.join(trips_today_df, \"shape_id\", \"inner\").select(shapes_df[\"*\"]).distinct()\n",
    "agency_today_df = agency_df.join(routes_today_df, \"agency_id\", \"inner\").select(agency_df[\"*\"]).distinct()\n",
    "stops_today_df = stops_df.join(stop_times_today_df, \"stop_id\", \"inner\").select(stops_df[\"*\"]).distinct()\n",
    "\n",
    "# 8. Display results\n",
    "print(\"==========================================================================\")\n",
    "agency_today_df.show(3, truncate=False)\n",
    "print(\"==========================================================================\")\n",
    "calendar_today_df.show(3, truncate=False)\n",
    "print(\"==========================================================================\")\n",
    "calendar_dates_today_df.show(3, truncate=False)\n",
    "print(\"==========================================================================\")\n",
    "routes_today_df.show(3, truncate=False)\n",
    "print(\"==========================================================================\")\n",
    "shapes_today_df.show(3, truncate=False)\n",
    "print(\"==========================================================================\")\n",
    "stops_today_df.show(3, truncate=False)\n",
    "print(\"==========================================================================\")\n",
    "stop_times_today_df.show(3, truncate=False)\n",
    "print(\"==========================================================================\")\n",
    "trips_today_df.show(3, truncate=False)\n",
    "print(\"==========================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a965e8a6-213f-4d3d-ac38-f0b0a8671bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================================================================================\n",
    "#=================================================================================================================\n",
    "#=================================================================================================================\n",
    "#=================================================================================================================\n",
    "#=================================================================================================================\n",
    "#=================================================================================================================\n",
    "#=================================================================================================================\n",
    "#================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1e5484-d369-4877-a833-74da5f5f8a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClichHouse Config Connection\n",
    "\n",
    "clickhouse_url = \"jdbc:clickhouse://clickhouse:8123/gtfs_batch\"\n",
    "clickhouse_properties = {\n",
    "    \"user\": \"default\",\n",
    "    \"password\": \"123\",\n",
    "    \"driver\": \"com.clickhouse.jdbc.ClickHouseDriver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc88d2c-3892-45e8-87e5-6cf5fa7ad021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calendar_today_df = calendar_today_df.withColumn(\"start_date\", to_date(\"start_date\", \"yyyyMMdd\"))\n",
    "# calendar_today_df = calendar_today_df.withColumn(\"end_date\", to_date(\"end_date\", \"yyyyMMdd\"))\n",
    "# calendar_dates_today_df = calendar_dates_today_df.withColumn(\"date\", to_date(\"date\", \"yyyyMMdd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be31a4be-cffb-409d-a097-9b74df0eb5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "agency_today_df.write.jdbc(clickhouse_url, \"agency\", mode=\"append\", properties=clickhouse_properties)\n",
    "calendar_today_df.repartition(50).write.jdbc(clickhouse_url, \"calendar\", mode=\"append\", properties=clickhouse_properties)\n",
    "calendar_dates_today_df.repartition(50).write.jdbc(clickhouse_url, \"calendar_dates\", mode=\"append\", properties=clickhouse_properties)\n",
    "routes_today_df.repartition(50).write.jdbc(clickhouse_url, \"routes\", mode=\"append\", properties=clickhouse_properties)\n",
    "shapes_today_df.repartition(50).write.jdbc(clickhouse_url, \"shapes\", mode=\"append\", properties=clickhouse_properties)\n",
    "stops_today_df.repartition(50).write.jdbc(clickhouse_url, \"stops\", mode=\"append\", properties=clickhouse_properties)\n",
    "trips_today_df.repartition(50).write.jdbc(clickhouse_url, \"trips\", mode=\"append\", properties=clickhouse_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f898cf-83ca-4e17-aca4-6c523288576f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]"
     ]
    }
   ],
   "source": [
    "stop_times_today_df.repartition(50).write.jdbc(clickhouse_url, \"stop_times\", mode=\"append\", properties=clickhouse_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cdce8f8-042a-41d4-9f46-258ea2f3a6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2390"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "for df in [\n",
    "    agency_df, calendar_df, calendar_dates_df, routes_df,\n",
    "    shapes_df, stops_df, stop_times_df, trips_df,\n",
    "    agency_today_df, calendar_today_df, calendar_dates_today_df, routes_today_df,\n",
    "    shapes_today_df, stops_today_df, stop_times_today_df, trips_today_df\n",
    "]:\n",
    "    df.unpersist(blocking=True)\n",
    "\n",
    "# Clear cache from Spark\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "# Stop Spark\n",
    "spark.stop()\n",
    "\n",
    "# Deleting variables from memory\n",
    "del agency_df, calendar_df, calendar_dates_df, routes_df\n",
    "del shapes_df, stops_df, stop_times_df, trips_df, spark\n",
    "del agency_today_df, calendar_today_df, calendar_dates_today_df, routes_today_df,\n",
    "del shapes_today_df, stops_today_df, stop_times_today_df, trips_today_df\n",
    "\n",
    "# Garbage collection imposed\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cdb912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
